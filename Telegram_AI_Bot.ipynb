{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/tugcebyrl/Telegram-AI-BOT/blob/main/Telegram_AI_Bot.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "K_APzOnL6jNr"
      },
      "outputs": [],
      "source": [
        "#!pip install python-telegram-bot==13.7"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "7oYsfO4RWbo8"
      },
      "outputs": [],
      "source": [
        "#!pip install tensorflow"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "whHOH_r0AjDT"
      },
      "source": [
        "# Import Modules\n",
        "* token to access the telegram bot api"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "82AFaEeO9j9r"
      },
      "outputs": [],
      "source": [
        "from telegram.ext import *\n",
        "from io import BytesIO\n",
        "import cv2\n",
        "import numpy as np\n",
        "import tensorflow as tf"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YynpseM-869f"
      },
      "outputs": [],
      "source": [
        "with open('/content/drive/MyDrive/Colab Notebooks/token.txt','r') as f:\n",
        "  telegram_token=f.read()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-nS_Jk0WBD0i"
      },
      "source": [
        "# Training Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2AWLtNvlA4S_"
      },
      "outputs": [],
      "source": [
        "(x_train,y_train),(x_test,y_test)=tf.keras.datasets.cifar10.load_data()\n",
        "x_train,x_test=x_train/255,x_test/255"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HGmL5k4YBV0U"
      },
      "outputs": [],
      "source": [
        "class_names=['Plane','Car','Cat','Horse','Deer','Rose','Frog','Ship','Mouse','Truck']"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "89piThcGGK-H"
      },
      "source": [
        "# Neural Network"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "J-dEdhL-B2wp"
      },
      "outputs": [],
      "source": [
        "model=tf.keras.models.Sequential()\n",
        "model.add(tf.keras.layers.Conv2D(32,(3,3),activation='relu',input_shape=(32,32,3)))\n",
        "model.add(tf.keras.layers.MaxPooling2D((2,2)))\n",
        "model.add(tf.keras.layers.Conv2D(64,(3,3),activation='relu'))\n",
        "model.add(tf.keras.layers.MaxPooling2D((2,2)))\n",
        "model.add(tf.keras.layers.Conv2D(64,(3,3),activation='relu'))\n",
        "model.add(tf.keras.layers.Flatten())\n",
        "model.add(tf.keras.layers.Dense(64,activation='relu'))\n",
        "model.add(tf.keras.layers.Dense(10,activation='softmax'))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VMav7RmuAf7D"
      },
      "source": [
        "# Basic Bot Settings"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tf1CYO2892PH"
      },
      "outputs": [],
      "source": [
        "def start(update,context):\n",
        "  update.message.reply_text(\"HELLO!\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fGHEi7Nd-L9K"
      },
      "outputs": [],
      "source": [
        "def help(update,context):\n",
        "  update.message.reply_text(\"\"\"\n",
        "  /start - Starts Conversation\n",
        "  /help - Messages\n",
        "  /train - Trains Network\n",
        "  \"\"\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AjLlD2QhKY4U"
      },
      "source": [
        "# Process images from users"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "B6xUMjx5_B8b"
      },
      "outputs": [],
      "source": [
        "def train(update,context):\n",
        "  update.message.reply_text(\"... Model is being trained ...\")\n",
        "  model.compile(optimizer='adam',loss='sparse_categorical_crossentropy',metrics=['accuracy'])\n",
        "  model.fit(x_train,y_train,epochs=10,validation_data=(x_test,y_test))\n",
        "  #model.save('cifar_classifier.model')\n",
        "  model.export('cifar_classifier')\n",
        "  update.message.reply_text(\"... Process Done! You can send pictures  ...\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8YXfO3UD_F6p"
      },
      "outputs": [],
      "source": [
        "def handle_message(update,context):\n",
        "  update.message.reply_text(\"Send image to train model\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DNMzakyb_Y0e"
      },
      "outputs": [],
      "source": [
        "def handle_photo(update,context):\n",
        "  file=context.bot.get_file(update.message.photo[-1].file_id)\n",
        "  f=BytesIO(file.download_as_bytearray())\n",
        "  file_bytes=np.asarray(bytearray(f.read()),dtype=np.uint8)\n",
        "\n",
        "  img=cv2.imdecode(file_bytes,cv2.IMREAD_COLOR)\n",
        "  img=cv2.cvtColor(img,cv2.COLOR_RGB2BGR)\n",
        "  img=cv2.resize(img,(32,32),interpolation=cv2.INTER_AREA)\n",
        "\n",
        "  pred=model.predict(np.array([img/255]))\n",
        "  update.message.reply_text(f\"I think the picture is a {class_names[np.argmax(pred)]}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pW-eGOML_dss"
      },
      "outputs": [],
      "source": [
        "updater = Updater(telegram_token,use_context=True)\n",
        "dp=updater.dispatcher"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5VC4tbAm_28Y"
      },
      "outputs": [],
      "source": [
        "dp.add_handler(CommandHandler(\"start\",start))\n",
        "dp.add_handler(CommandHandler(\"help\",help))\n",
        "dp.add_handler(CommandHandler(\"train\",train))\n",
        "dp.add_handler(MessageHandler(Filters.text,handle_message))\n",
        "dp.add_handler(MessageHandler(Filters.photo,handle_photo))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "N1poCiTQARK9",
        "outputId": "90e7cae2-95f3-452f-92d2-0b1b405240f5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m94s\u001b[0m 59ms/step - accuracy: 0.3465 - loss: 1.7548 - val_accuracy: 0.5520 - val_loss: 1.2383\n",
            "Epoch 2/10\n",
            "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m130s\u001b[0m 51ms/step - accuracy: 0.5757 - loss: 1.2013 - val_accuracy: 0.5988 - val_loss: 1.1182\n",
            "Epoch 3/10\n",
            "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m91s\u001b[0m 58ms/step - accuracy: 0.6433 - loss: 1.0206 - val_accuracy: 0.6512 - val_loss: 0.9825\n",
            "Epoch 4/10\n",
            "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m131s\u001b[0m 51ms/step - accuracy: 0.6797 - loss: 0.9152 - val_accuracy: 0.6722 - val_loss: 0.9307\n",
            "Epoch 5/10\n",
            "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m80s\u001b[0m 51ms/step - accuracy: 0.7087 - loss: 0.8277 - val_accuracy: 0.6883 - val_loss: 0.8990\n",
            "Epoch 6/10\n",
            "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m83s\u001b[0m 52ms/step - accuracy: 0.7299 - loss: 0.7690 - val_accuracy: 0.6917 - val_loss: 0.8908\n",
            "Epoch 7/10\n",
            "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m79s\u001b[0m 50ms/step - accuracy: 0.7500 - loss: 0.7110 - val_accuracy: 0.6776 - val_loss: 0.9678\n",
            "Epoch 8/10\n",
            "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m83s\u001b[0m 51ms/step - accuracy: 0.7643 - loss: 0.6725 - val_accuracy: 0.6933 - val_loss: 0.9220\n",
            "Epoch 9/10\n",
            "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m81s\u001b[0m 52ms/step - accuracy: 0.7797 - loss: 0.6247 - val_accuracy: 0.7028 - val_loss: 0.8928\n",
            "Epoch 10/10\n",
            "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m85s\u001b[0m 54ms/step - accuracy: 0.7946 - loss: 0.5779 - val_accuracy: 0.7042 - val_loss: 0.8889\n",
            "Saved artifact at 'cifar_classifier'. The following endpoints are available:\n",
            "\n",
            "* Endpoint 'serve'\n",
            "  args_0 (POSITIONAL_ONLY): TensorSpec(shape=(None, 32, 32, 3), dtype=tf.float32, name='keras_tensor')\n",
            "Output Type:\n",
            "  TensorSpec(shape=(None, 10), dtype=tf.float32, name=None)\n",
            "Captures:\n",
            "  136962059180288: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  136962059178880: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  136962059188560: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  136962059188032: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  136962059688192: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  136962059690480: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  136962059692768: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  136962059696288: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  136962059695760: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  136962059697872: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 112ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step\n"
          ]
        }
      ],
      "source": [
        "updater.start_polling()\n",
        "updater.idle()"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNv2MX6LL93Gtg8MGNas6wO",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}